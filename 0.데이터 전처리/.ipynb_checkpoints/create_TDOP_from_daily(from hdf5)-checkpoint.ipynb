{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append('../data/')\n",
    "import tables as tb\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3 as lite\n",
    "from model import DateMapper, Minute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 일별 OHLC 변환하여 TDOP (Trade Density Over Price) 만들기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "``daily futrues.h5`` does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-d1684610dedc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/raw data/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'daily futrues.h5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Python\\Miniconda64\\lib\\site-packages\\tables\\file.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filename, mode, title, root_uep, filters, **kwargs)\u001b[0m\n\u001b[0;32m    782\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m         \u001b[1;31m# Now, it is time to initialize the File extension\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 784\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_g_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    785\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m         \u001b[1;31m# Check filters and set PyTables format version for new files.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mtables\\hdf5extension.pyx\u001b[0m in \u001b[0;36mtables.hdf5extension.File._g_new (tables\\hdf5extension.c:4654)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Miniconda64\\lib\\site-packages\\tables\\utils.py\u001b[0m in \u001b[0;36mcheck_file_access\u001b[1;34m(filename, mode)\u001b[0m\n\u001b[0;32m    155\u001b[0m         \u001b[1;31m# The file should be readable.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mF_OK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"``%s`` does not exist\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"``%s`` is not a regular file\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: ``daily futrues.h5`` does not exist"
     ]
    }
   ],
   "source": [
    "sys.path.append('../data/raw data/')\n",
    "db = tb.File('daily_futrues.h5', mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#종목정보 불러오기\n",
    "con = lite.connect('data/db.sqlite3')\n",
    "products = pd.read_sql('select * from trading_product', con)\n",
    "products.set_index(['group'], drop=False, inplace=True)\n",
    "products = products.to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#테이블 삭제후 생성\n",
    "for group in db.iter_nodes('/'):\n",
    "    #group.DateMapper.remove()\n",
    "    #group.Minute.remove()\n",
    "    db.create_table(group, 'DateMapper', DateMapper)\n",
    "    db.create_table(group, 'Minute', Minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everythin fin.\n"
     ]
    }
   ],
   "source": [
    "for group in db.iter_nodes('/'):\n",
    "    grpname = group._v_name\n",
    "    name = group._v_title\n",
    "    #print(group._v_name)\n",
    "\n",
    "    data = []\n",
    "    dates = []\n",
    "    #db cursors\n",
    "    datecur = group.DateMapper \n",
    "    minute = group.Minute\n",
    "        \n",
    "    #환경변수\n",
    "    tick_unit = products[grpname]['tick_unit']\n",
    "    digit = products[grpname]['decimal_places']\n",
    "        \n",
    "    #pandas dataframe\n",
    "    df = pd.DataFrame(group.Daily.read()).sort_values('date', ascending=True)\n",
    "    \n",
    "    for row in df.itertuples():\n",
    "        idx = len(dates) #datemapper\n",
    "        \n",
    "        if round(row.low, digit) == round(row.high, digit):\n",
    "            item = (idx, round(row.low, digit), row.volume)\n",
    "            dateitem = (row.date, idx)\n",
    "            data.append(item)\n",
    "            dates.append(dateitem)\n",
    "        \n",
    "        else:\n",
    "            length = (row.high - row.low)/tick_unit + 1\n",
    "            length = np.rint(length)\n",
    "            value = row.volume/length\n",
    "            \n",
    "            if np.isinf(value) or (value < 0.1): #inf 또는 틱탕 너무 작은 value 버림\n",
    "                #print(\"wrong volume\", row.volume, length, name, str(row.date.astype('M8[s]').astype('M8[D]')))\n",
    "                continue\n",
    "            else:\n",
    "                dateitem = (row.date, idx)\n",
    "                dates.append(dateitem)\n",
    "                for price in np.arange(round(row.low, digit), row.high-tick_unit/2, tick_unit):\n",
    "                    item = (idx, price, value)\n",
    "                    data.append(item)\n",
    "    if dates:\n",
    "        datecur.append(dates)\n",
    "        minute.append(data)\n",
    "        minute.flush()\n",
    "        datecur.flush()\n",
    "print(\"Everythin fin.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 중복데이터 체크\n",
    "from collections import Counter\n",
    "\n",
    "for grp in db.iter_nodes('/'):\n",
    "    item = grp.DateMapper.cols.date[:]\n",
    "    dup = [item for item, count in Counter(df2).items() if count > 1]\n",
    "    if dup:\n",
    "        print(grp._v_title, \" has duplicated data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
